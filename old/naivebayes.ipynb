{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Naive Bayes Classifier</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[2], line 48\u001b[0m\n\u001b[1;32m     46\u001b[0m fitur_counts \u001b[38;5;241m=\u001b[39m {}\n\u001b[1;32m     47\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mlen\u001b[39m(data_training[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mclass\u001b[39m\u001b[38;5;124m\"\u001b[39m])):\n\u001b[0;32m---> 48\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[43mdata_training\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mclass\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m]\u001b[49m \u001b[38;5;241m==\u001b[39m kelas:\n\u001b[1;32m     49\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m data_training[fitur][i] \u001b[38;5;129;01min\u001b[39;00m fitur_counts:\n\u001b[1;32m     50\u001b[0m             fitur_counts[data_training[fitur][i]] \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/pandas/core/series.py:1121\u001b[0m, in \u001b[0;36mSeries.__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   1118\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_values[key]\n\u001b[1;32m   1120\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m key_is_scalar:\n\u001b[0;32m-> 1121\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_value\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1123\u001b[0m \u001b[38;5;66;03m# Convert generator to list before going through hashable part\u001b[39;00m\n\u001b[1;32m   1124\u001b[0m \u001b[38;5;66;03m# (We will iterate through the generator there to check for slices)\u001b[39;00m\n\u001b[1;32m   1125\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_iterator(key):\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/pandas/core/series.py:1237\u001b[0m, in \u001b[0;36mSeries._get_value\u001b[0;34m(self, label, takeable)\u001b[0m\n\u001b[1;32m   1234\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_values[label]\n\u001b[1;32m   1236\u001b[0m \u001b[38;5;66;03m# Similar to Index.get_value, but we do not fall back to positional\u001b[39;00m\n\u001b[0;32m-> 1237\u001b[0m loc \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mindex\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlabel\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1239\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_integer(loc):\n\u001b[1;32m   1240\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_values[loc]\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "data_training = pd.read_excel(\"./data/data_anotation.xlsx\")\n",
    "# Data Training\n",
    "# data_training = {\n",
    "#     \"currentWord\": [\"kamis\", \"10\", \"maret\"],\n",
    "#     \"token\":[\"word\",\"number\"],\n",
    "#     \"currentTag\": [\"NN\", \"CD\", \"NN\"],\n",
    "#     \"bef1tag\": [\"null\", \"NN\", \"CD\"],\n",
    "#     \"class\": [\"B-waktu\", \"B-tanggal\", \"I-Tanggal\"]\n",
    "# }\n",
    "\n",
    "# Data Testing\n",
    "data_testing = {\n",
    "    \"currentWord\": \"banjir\",\n",
    "    \"currentTag\": \"NN\",\n",
    "    \"bef1tag\": \"NN\",\n",
    "    \"token\":\"Word\",\n",
    "    \"class\": \"?\"\n",
    "}\n",
    "\n",
    "# Step 1: Menghitung Probabilitas Kelas\n",
    "total_data = len(data_training[\"class\"])\n",
    "kelas_counts = {}\n",
    "for kelas in data_training[\"class\"]:\n",
    "    if kelas in kelas_counts:\n",
    "        kelas_counts[kelas] += 1\n",
    "    else:\n",
    "        kelas_counts[kelas] = 1\n",
    "\n",
    "probabilitas_kelas = {}\n",
    "for kelas, count in kelas_counts.items():\n",
    "    probabilitas_kelas[kelas] = count / total_data\n",
    "\n",
    "# print(f'probabilitas setiap kelas:')\n",
    "# pprint.pprint(probabilitas_kelas)\n",
    "\n",
    "\n",
    "# Step 2: Menghitung Probabilitas setiap fitur (currentword, token, posttag, bef1tag)\n",
    "probabilitas_fitur = {}\n",
    "for kelas in probabilitas_kelas:\n",
    "    probabilitas_fitur[kelas] = {}\n",
    "    for fitur in data_training.keys():\n",
    "        if fitur != \"class\":\n",
    "            probabilitas_fitur[kelas][fitur] = {}\n",
    "\n",
    "            fitur_counts = {}\n",
    "            for i in range(len(data_training[\"class\"])):\n",
    "                if data_training[\"class\"][i] == kelas:\n",
    "                    if data_training[fitur][i] in fitur_counts:\n",
    "                        fitur_counts[data_training[fitur][i]] += 1\n",
    "                    else:\n",
    "                        fitur_counts[data_training[fitur][i]] = 1\n",
    "\n",
    "            for value, count in fitur_counts.items():\n",
    "                probabilitas_fitur[kelas][fitur][value] = count / kelas_counts[kelas]\n",
    "\n",
    "# print(f'probabilitas setiap fitur:')\n",
    "# pprint.pprint(probabilitas_fitur)\n",
    "\n",
    "# Step 3: Menghitung Probabilitas Gabungan\n",
    "probabilitas_gabungan = {}\n",
    "for kelas in probabilitas_kelas:\n",
    "    probabilitas_gabungan[kelas] = probabilitas_kelas[kelas]\n",
    "    for fitur in data_testing.keys():\n",
    "        if fitur != \"class\":\n",
    "            if (\n",
    "                fitur not in probabilitas_fitur[kelas]\n",
    "                or data_testing[fitur] not in probabilitas_fitur[kelas][fitur]\n",
    "            ):\n",
    "                continue\n",
    "            probabilitas_gabungan[kelas] *= probabilitas_fitur[kelas][fitur][\n",
    "                data_testing[fitur]\n",
    "            ]\n",
    "\n",
    "# print(f'probabilitas Gabungan:')\n",
    "# pprint.pprint(probabilitas_gabungan)\n",
    "\n",
    "# Step 4: Menentukan Class\n",
    "maks_prob = 0\n",
    "pred_class = None\n",
    "for kelas, prob in probabilitas_gabungan.items():\n",
    "    if prob > maks_prob:\n",
    "        maks_prob = prob\n",
    "        pred_class = kelas\n",
    "\n",
    "# Step 5: Mengembalikan Class yang Diprediksi\n",
    "predicted_class = pred_class\n",
    "print(\"Predicted Class:\", predicted_class)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
